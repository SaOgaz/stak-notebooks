{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stsdas.toolbox.imgtools.mstools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to handle HST imsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='notes'></a>\n",
    "\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For questions or comments please see** [our github page](https://github.com/spacetelescope/stak).  **We encourage and appreciate user feedback.**\n",
    "\n",
    "**Most of these notebooks rely on basic knowledge of the Astropy FITS I/O module.  If you are unfamiliar with this module please see the** [Astropy FITS I/O user documentation](http://docs.astropy.org/en/stable/io/fits/) **before using this documentation**.\n",
    "\n",
    "The imgtools.mstools package contains tasks for working with STIS, NICMOS, ACS, and WFC3 data. Some tasks are 'extensions\" of existing tasks in the STSDAS system, and support other instruments/file formats as well.\n",
    "\n",
    "\n",
    "Contents:\n",
    "\n",
    "* [ecdel-ecextract-extdel-msdel-msjoin-mssplit](#ecdel-ecextract-extdel-msdel-msjoin-mssplit)\n",
    "* [mscombine](#mscombine)\n",
    "* [msstatistics](#msstatistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ecdel-ecextract-extdel-msdel-msjoin-mssplit'></a>\n",
    "\n",
    "## ecdel-ecextract-extdel-msdel-msjoin-mssplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please review the** [Notes](#notes) **section above before running any examples in this notebook**\n",
    "\n",
    "These tasks contain various methods for deleting or moving extensions around in FITS files.  This can be easily done using the `astropy.io.fits` module in Astropy.  Here is a [good page](http://docs.astropy.org/en/stable/io/fits/) to familarize yourself with this package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mscombine'></a>\n",
    "\n",
    "## mscombine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please review the** [Notes](#notes) **section above before running any examples in this notebook**\n",
    "\n",
    "The original `mscombine` IRAF task performed image combination of several `SCI` exetensions of HST data while allowing the user to reject specified `DQ` bits. Additionally, the user could choose to combine the stack using the average or the median.  \n",
    "\n",
    "This `mscombine` alternative uses `numpy` masked arrays to avoid using flagged pixels in the `DQ` array.  In this simple example, we average-combine several full-frame WFC3/UVIS images.\n",
    "\n",
    "Tasks for image combination are currently being developed in the ``CCDPROC`` package, see the [CCDPROC doc page](https://ccdproc.readthedocs.io/en/latest/#) for more details or the **images.imutil.imsum** task for a short usage example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Astronomy Specific Imports\n",
    "from astropy.io import fits\n",
    "from stsci.tools.bitmask import bitfield_to_boolean_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "test_data = glob.glob('/eng/ssb/iraf_transition/test_data/mscombine/nnicpw4*_blv_tmp.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masked arrays\n",
    "masked_arrays_ext1, masked_arrays_ext2, masked_arrays_ext4, masked_arrays_ext5 = [], [], [], []\n",
    "for filename in test_data:\n",
    "    with fits.open(filename) as hdulist:\n",
    "        \n",
    "        # For UVIS chip 2, using DQ flags 32 and 64 (96 bitflag)\n",
    "        mask_ext3 = np.bitwise_and(hdulist[3].data, 96) != 0\n",
    "        masked_arrays_ext1.append(np.ma.masked_array(hdulist[1].data, mask=mask_ext3))\n",
    "        masked_arrays_ext2.append(np.ma.masked_array(hdulist[2].data, mask=mask_ext3))\n",
    "\n",
    "        # For UVIS chip 1            \n",
    "        mask_ext6 = np.bitwise_and(hdulist[6].data, 96) != 0\n",
    "        masked_arrays_ext4.append(np.ma.masked_array(hdulist[4].data, mask=mask_ext6))\n",
    "        masked_arrays_ext5.append(np.ma.masked_array(hdulist[5].data, mask=mask_ext6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average-combine SCI arrays\n",
    "comb_ext1 = np.ma.mean(masked_arrays_ext1, axis=0).data\n",
    "comb_ext4 = np.ma.mean(masked_arrays_ext4, axis=0).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ogaz/miniconda2/envs/irafdev3/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/ogaz/miniconda2/envs/irafdev3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Propoagate uncertainties for ERR arrays, divide by zero expected\n",
    "weight_image_ext1 = np.zeros((2051, 4096))\n",
    "weight_image_ext4 = np.zeros((2051, 4096))\n",
    "for array in masked_arrays_ext1:\n",
    "    mask = array.mask\n",
    "    weight_image_ext1[np.where(mask == False)] += 1.0\n",
    "for array in masked_arrays_ext4:\n",
    "    mask = array.mask\n",
    "    weight_image_ext4[np.where(mask == False)] += 1.0\n",
    "masked_arrays_ext2_squared = [(item * (1/weight_image_ext1))**2 for item in masked_arrays_ext2]\n",
    "masked_arrays_ext5_squared = [(item * (1/weight_image_ext4))**2 for item in masked_arrays_ext5]\n",
    "comb_ext2 = np.sqrt(np.ma.sum(masked_arrays_ext2_squared, axis=0)).data\n",
    "comb_ext5 = np.sqrt(np.ma.sum(masked_arrays_ext5_squared, axis=0)).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create empty DQ arrays\n",
    "comb_ext3 = np.zeros((2051, 4096))\n",
    "comb_ext6 = np.zeros((2051, 4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build and save the combined file, using the first final for the header\n",
    "hdu0 = fits.PrimaryHDU(header=fits.getheader(test_data[0], 0))\n",
    "hdu1 = fits.ImageHDU(comb_ext1, header=fits.getheader(test_data[0], 0))\n",
    "hdu2 = fits.ImageHDU(comb_ext2, header=fits.getheader(test_data[0], 1))\n",
    "hdu3 = fits.ImageHDU(comb_ext3, header=fits.getheader(test_data[0], 2))\n",
    "hdu4 = fits.ImageHDU(comb_ext4, header=fits.getheader(test_data[0], 3))\n",
    "hdu5 = fits.ImageHDU(comb_ext5, header=fits.getheader(test_data[0], 4))\n",
    "hdu6 = fits.ImageHDU(comb_ext6, header=fits.getheader(test_data[0], 5))\n",
    "hdulist = fits.HDUList([hdu0, hdu1, hdu2, hdu3, hdu4, hdu5, hdu6])\n",
    "hdulist.writeto('mscombine_test.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='msstatistics'></a>\n",
    "\n",
    "## msstatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please review the** [Notes](#notes) **section above before running any examples in this notebook**\n",
    "\n",
    "The msstatictics task is similar to images.imutil.imstatistics, but with the added capability to mask using an HST DQ array. Below we show an example of this using multiple files and the [sigma_clipped_stats](http://docs.astropy.org/en/stable/api/astropy.stats.sigma_clipped_stats.html) function. For more examples on array statistics please see the images.imutil.imstatistics notebook entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Astronomy Specific Imports\n",
    "from astropy.io import fits\n",
    "from astropy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for file: /eng/ssb/iraf_transition/test_data/iczgs3ygq_flt.fits\n",
      "mean: 0.820129451464822\n",
      "median: 0.8166738748550415\n",
      "standard deviation: 0.05532484610965952\n",
      "\n",
      "Stats for file: /eng/ssb/iraf_transition/test_data/iczgs3ygq_newdtype_flt.fits\n",
      "mean: 1.0\n",
      "median: 1.0\n",
      "standard deviation: 0.0\n",
      "\n",
      "Stats for file: /eng/ssb/iraf_transition/test_data/iczgs3y5q_flt.fits\n",
      "mean: 0.7803241408189818\n",
      "median: 0.7780539989471436\n",
      "standard deviation: 0.049491070357460455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Change these values to your desired data file list\n",
    "# loop over multiple files, make filelist\n",
    "test_files = glob.glob('/eng/ssb/iraf_transition/test_data/i*_flt.fits')\n",
    "\n",
    "for filename in test_files:\n",
    "    #test_data = '/eng/ssb/iraf_transition/test_data/iczgs3y5q_flt.fits\n",
    "    hdulist = fits.open(filename)\n",
    "\n",
    "    # Make mask using Python bitmath, using bit flags 32 and 4\n",
    "    # Add the values of the flags you would like to mask, and use\n",
    "    # that value in the np.bitwise_and call.\n",
    "    boolean_mask = np.bitwise_and(hdulist[3].data, 36) != 0\n",
    "\n",
    "    # The sigma_clipped_stats function returns the mean, median, and stddev respectively\n",
    "    mean, median, std = stats.sigma_clipped_stats(hdulist[1].data, mask=boolean_mask, sigma=2.0, iters=3)\n",
    "    print(\"Stats for file: {}\".format(filename))\n",
    "    print(\"mean: {}\".format(mean))\n",
    "    print(\"median: {}\".format(median))\n",
    "    print(\"standard deviation: {}\\n\".format(std))\n",
    "\n",
    "    # Close fits file\n",
    "    hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Replacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* msarith - Image arithmetic with NICMOS and STIS files. See **images.imutil.imarith**.\n",
    "* mscopy - Copy image sets of a multi-extension FITS file. See **images.imutil.imcopy**\n",
    "* mssort - Sort a FITS file to get all extensions of like version number. Deprecated."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
